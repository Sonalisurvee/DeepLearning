{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45408225-e749-4ca8-8fa6-ea61d2e80dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sonal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\sonal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sonal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sonal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sonal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sonal\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332da4d6-c10f-4752-aca4-5f91aaed53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"By 55,000 years ago, the first modern humans, or Homo sapiens, had arrived on the Indian subcontinent from Africa, where they had earlier evolved.[27][28][29] The earliest known modern human remains in South Asia date to about 30,000 years ago.[27] After 6500 BCE, evidence for domestication of food crops and animals, construction of permanent structures, and storage of agricultural surplus appeared in Mehrgarh and other sites in Balochistan, Pakistan.[83] These gradually developed into the Indus Valley Civilisation,[84][83] the first urban culture in South Asia,[85] which flourished during 2500–1900 BCE in Pakistan and western India.[86] Centred around cities such as Mohenjo-daro, Harappa, Dholavira, and Kalibangan, and relying on varied forms of subsistence, the civilisation engaged robustly in crafts production and wide-ranging trade.[85]\n",
    "\n",
    "During the period 2000–500 BCE, many regions of the subcontinent transitioned from the Chalcolithic cultures to the Iron Age ones.[87] The Vedas, the oldest scriptures associated with Hinduism,[88] were composed during this period,[89] and historians have analysed these to posit a Vedic culture in the Punjab region and the upper Gangetic Plain.[87] Most historians also consider this period to have encompassed several waves of Indo-Aryan migration into the subcontinent from the north-west.[88] The caste system, which created a hierarchy of priests, warriors, and free peasants, but which excluded indigenous peoples by labelling their occupations impure, arose during this period.[90] On the Deccan Plateau, archaeological evidence from this period suggests the existence of a chiefdom stage of political organisation.[87] In South India, a progression to sedentary life is indicated by the large number of megalithic monuments dating from this period,[91] as well as by nearby traces of agriculture, irrigation tanks, and craft traditions.[91]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde86f11-14ad-4755-87ae-7b8acc6be9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "# libreries to use in nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd84655-44e5-4cbb-ae52-44bfd244f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokkenization - convert para to sentenes\n",
    "# nltk.download('punkt')\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99d41cb-0981-4f15-b208-32536e4b3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4ff8d9-c649-43ed-bd15-4932b7110c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300593d2-6d3e-481c-bddd-31e6d635294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eedad1b3-5df6-45b1-9681-015d592b0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248525fa-4650-4c84-b16f-6035a1b71782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re - regular expression\n",
    "import re\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    # used to replace the special char\n",
    "    review = review.lower()\n",
    "    # review = review.split()\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed70aee4-2c88-4c60-b7f2-2cfcdef6e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e93c8f2-1e00-41d2-bca4-e8d897aa4c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "ago\n",
      "first\n",
      "modern\n",
      "human\n",
      "homo\n",
      "sapiens\n",
      "arrived\n",
      "indian\n",
      "subcontinent\n",
      "africa\n",
      "earlier\n",
      "evolved\n",
      "earliest\n",
      "known\n",
      "modern\n",
      "human\n",
      "remains\n",
      "south\n",
      "asia\n",
      "date\n",
      "year\n",
      "ago\n",
      "bce\n",
      "evidence\n",
      "domestication\n",
      "food\n",
      "crop\n",
      "animal\n",
      "construction\n",
      "permanent\n",
      "structure\n",
      "storage\n",
      "agricultural\n",
      "surplus\n",
      "appeared\n",
      "mehrgarh\n",
      "site\n",
      "balochistan\n",
      "pakistan\n",
      "gradually\n",
      "developed\n",
      "indus\n",
      "valley\n",
      "civilisation\n",
      "first\n",
      "urban\n",
      "culture\n",
      "south\n",
      "asia\n",
      "flourished\n",
      "bce\n",
      "pakistan\n",
      "western\n",
      "india\n",
      "centred\n",
      "around\n",
      "city\n",
      "mohenjo\n",
      "daro\n",
      "harappa\n",
      "dholavira\n",
      "kalibangan\n",
      "relying\n",
      "varied\n",
      "form\n",
      "subsistence\n",
      "civilisation\n",
      "engaged\n",
      "robustly\n",
      "craft\n",
      "production\n",
      "wide\n",
      "ranging\n",
      "trade\n",
      "period\n",
      "bce\n",
      "many\n",
      "region\n",
      "subcontinent\n",
      "transitioned\n",
      "chalcolithic\n",
      "culture\n",
      "iron\n",
      "age\n",
      "one\n",
      "veda\n",
      "oldest\n",
      "scripture\n",
      "associated\n",
      "hinduism\n",
      "composed\n",
      "period\n",
      "historian\n",
      "analysed\n",
      "posit\n",
      "vedic\n",
      "culture\n",
      "punjab\n",
      "region\n",
      "upper\n",
      "gangetic\n",
      "plain\n",
      "historian\n",
      "also\n",
      "consider\n",
      "period\n",
      "encompassed\n",
      "several\n",
      "wave\n",
      "indo\n",
      "aryan\n",
      "migration\n",
      "subcontinent\n",
      "north\n",
      "west\n",
      "caste\n",
      "system\n",
      "created\n",
      "hierarchy\n",
      "priest\n",
      "warrior\n",
      "free\n",
      "peasant\n",
      "excluded\n",
      "indigenous\n",
      "people\n",
      "labelling\n",
      "occupation\n",
      "impure\n",
      "arose\n",
      "period\n",
      "deccan\n",
      "plateau\n",
      "archaeological\n",
      "evidence\n",
      "period\n",
      "suggests\n",
      "existence\n",
      "chiefdom\n",
      "stage\n",
      "political\n",
      "organisation\n",
      "south\n",
      "india\n",
      "progression\n",
      "sedentary\n",
      "life\n",
      "indicated\n",
      "large\n",
      "number\n",
      "megalithic\n",
      "monument\n",
      "dating\n",
      "period\n",
      "well\n",
      "nearby\n",
      "trace\n",
      "agriculture\n",
      "irrigation\n",
      "tank\n",
      "craft\n",
      "tradition\n"
     ]
    }
   ],
   "source": [
    "# # lemmatization\n",
    "for i in corpus:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(lemmetizer.lemmatize(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0be067fa-d0d1-499a-b894-7090ee8e3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # STOPWORDS ,lemmatization\n",
    "import re\n",
    "corpus = []\n",
    "for i in range(len(sentences)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmetizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f43c1d1-d82a-426a-ae50-b961992e6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4f1e3d7-5099-407a-818f-39157b1e09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW -bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a0fd799-ce7b-4944-b51a-d61bca8988a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for binary,like if there is 2 the n we will count itas 1\n",
    "cv = CountVectorizer(binary=True,ngram_range=(2,3))\n",
    "x = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebfe919-fa5a-440c-a507-325085753a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(binary=True,ngram_range=(3,3))\n",
    "# trigram\n",
    "#  'indian subcontinent': 136,\n",
    "#  'subcontinent africa': 247,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27003cf9-7427-411e-ad36-408f746012ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(binary=True,ngram_range=(2,3))\n",
    "# both tri and bi\n",
    "#  'sapiens arrived': 226,\n",
    " # 'arrived indian': 22,\n",
    " # 'indian subcontinent': 136,\n",
    " # 'subcontinent africa': 247,\n",
    "\n",
    "\n",
    "# her more sparsity,dim r more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9db719d1-377c-41d2-a060-a2d7fd5c4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "760ec648-8643-4b08-860a-30150d832bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].toarray()\n",
    "# here more sparsity,dim r more fro (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c44ed3a4-da1a-4379-b24a-152f7343a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f4e299d-1f26-4e4e-a05b-ed972818a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer()\n",
    "x = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "223d6c8f-b22b-4689-83a6-5da51469c6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'year ago first modern human homo sapiens arrived indian subcontinent africa earlier evolved'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ebec184-ae04-4249-8849-dfb8f2d7b4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x137 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af666ffe-a463-4c2f-8405-2aea4b99fe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29796609, 0.        , 0.25589674, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29796609, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29796609, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.29796609, 0.        ,\n",
       "        0.        , 0.25589674, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29796609, 0.25589674, 0.        ,\n",
       "        0.        , 0.29796609, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.25589674, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.29796609, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.22604806,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25589674]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16a6701c-1c65-4ab6-89ca-edaeecadf234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30151134, 0.30151134, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30151134, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.30151134, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30151134, 0.30151134, 0.        , 0.        , 0.        ,\n",
       "        0.30151134, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.30151134, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.30151134,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30151134, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.30151134]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngrams\n",
    "cvv = TfidfVectorizer(ngram_range=(3,3))\n",
    "y = cvv.fit_transform(corpus)\n",
    "y[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "774cd06d-b01a-485f-8241-49b027f54da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a5743de-fc4e-49b7-a2b9-dc87bee80078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.59972576, 0.        , 0.        , 0.52977168, 0.59972576]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max feature\n",
    "# it mean top 10 frequncy only takken for matrix\n",
    "cv_max = TfidfVectorizer(ngram_range=(1,1),max_features=10)\n",
    "y_max = cv_max.fit_transform(corpus)\n",
    "y_max[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c4e75a3-59c1-4303-98f6-a0f6e606180a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': 9,\n",
       " 'first': 5,\n",
       " 'subcontinent': 8,\n",
       " 'south': 7,\n",
       " 'bce': 0,\n",
       " 'evidence': 4,\n",
       " 'civilisation': 1,\n",
       " 'culture': 3,\n",
       " 'craft': 2,\n",
       " 'period': 6}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_max.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5685e770-b17f-4879-8336-a50b5c5d9925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
